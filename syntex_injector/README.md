# SYNTEX Workflow - AI Training Pipeline

**Production-Ready System fÃ¼r SYNTEX-Kalibrierung mit Llama 3**

Entwickelt fÃ¼r Resonanz-basierte semantische Feld-Analyse mit menschlicher Terminologie.

---

## ğŸ¯ Was ist SYNTEX?

**SYNTEX** ist ein neues Paradigma fÃ¼r AI-Analyse:
```
Alte Welt: Token-Prediction â†’ "Was kommt als nÃ¤chstes?"
SYNTEX: Feld-Kalibrierung â†’ "Wo IST das System?"
```

### **Kernprinzip:**

**Bedeutung existiert als Resonanzfeld** - SYNTEX misst und kalibriert diese Felder direkt, statt sie Ã¼ber Tokens zu approximieren.

---

## ğŸ—ï¸ System-Architektur
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPT-4o     â”‚ Generiert Meta-Prompts
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SYNTEX      â”‚ Wrapper mit 6 Feldern
â”‚ Framework   â”‚ (menschliche Terminologie)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Llama 3     â”‚ Kalibriert Resonanzfelder
â”‚ (7B)        â”‚ Antwortet wie ein Mensch
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Enhanced    â”‚ Parser, Scorer, Tracker
â”‚ Analytics   â”‚ Quality Score: 98/100
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Installation

### Voraussetzungen

- Python 3.10+
- OpenAI API Key
- Llama 3 Endpoint (lokal oder remote)

### Setup
```bash
# Repository klonen
cd /opt
git clone https://github.com/YOUR_USERNAME/syntx-workflow-api-get-prompts.git
cd syntx-workflow-api-get-prompts

# Branch wechseln
git checkout syntx-trainer

# Dependencies
pip3 install "openai>=1.0.0" requests

# API Key setzen
export OPENAI_API_KEY="sk-proj-..."
echo 'export OPENAI_API_KEY="sk-proj-..."' >> ~/.bashrc
```

---

## ğŸš€ Quick Start

### 1. Einzelner SYNTEX-kalibrierter Prompt
```bash
cd syntex_injector
python3 inject_syntex_enhanced.py -f ../prompts/test.txt
```

**Output:**
```
âœ… Kalibrierung erfolgreich (36s)
ğŸ“Š SYNTEX Quality Score: 98/100
   Field Completeness: 100/100
   
âœ… DRIFT
âœ… HINTERGRUND_MUSTER
âœ… DRUCKFAKTOREN
âœ… TIEFE
âœ… WIRKUNG
âœ… KLARTEXT
```

### 2. Komplette Pipeline (GPT â†’ SYNTEX â†’ Llama)
```bash
cd syntex_injector
python3 syntex_pipeline.py -t "KÃ¼nstliche Intelligenz" -s kreativ
```

**Das macht:**
1. GPT-4 generiert Meta-Prompt
2. SYNTEX Wrapper drum
3. Llama kalibriert
4. Combined Analytics

### 3. Batch-Processing
```bash
cd syntex_injector
python3 syntex_pipeline.py -b 10
```

Generiert 10 Random Topics durch die Pipeline.

---

## ğŸ“ Projekt-Struktur
```
syntx-workflow-api-get-prompts/
â”œâ”€â”€ gpt_generator/               # GPT-4 Prompt Generator
â”‚   â”œâ”€â”€ syntx_prompt_generator.py
â”‚   â”œâ”€â”€ batch_generator.py
â”‚   â”œâ”€â”€ topics_database.py       # 56 Topics
â”‚   â”œâ”€â”€ prompt_scorer.py
â”‚   â””â”€â”€ cost_tracker.py
â”‚
â”œâ”€â”€ syntex_injector/             # SYNTEX Kalibrierungs-System
â”‚   â”œâ”€â”€ syntex/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ wrapper.py       # SYNTEX Framework Loader
â”‚   â”‚   â”‚   â”œâ”€â”€ parser.py        # Response Parser
â”‚   â”‚   â”‚   â”œâ”€â”€ calibrator.py    # Basic Calibrator
â”‚   â”‚   â”‚   â””â”€â”€ calibrator_enhanced.py  # Mit Analytics
â”‚   â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ scorer.py        # Quality Scoring (0-100)
â”‚   â”‚   â”‚   â””â”€â”€ tracker.py       # Progress Tracking
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py        # Llama API Client
â”‚   â”‚   â”‚   â””â”€â”€ config.py        # Endpoints & Params
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ exceptions.py    # Custom Exceptions
â”‚   â”‚
â”‚   â”œâ”€â”€ inject_syntex.py         # Basic Injector
â”‚   â”œâ”€â”€ inject_syntex_enhanced.py  # Mit Scoring
â”‚   â”œâ”€â”€ syntex_pipeline.py       # Complete Pipeline
â”‚   â””â”€â”€ syntex_wrapper.txt       # Framework Template
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ gpt_prompts.jsonl        # GPT-4 Outputs
â”‚   â”œâ”€â”€ syntex_calibrations.jsonl  # Llama Outputs
â”‚   â””â”€â”€ syntex_progress.jsonl    # Quality Tracking
â”‚
â””â”€â”€ README.md
```

---

## ğŸ¨ SYNTEX Framework

### Die 6 Felder (Menschliche Terminologie)
```
1. DRIFT
   â†’ Beschreibt StabilitÃ¤t vs. VerÃ¤nderung
   â†’ "Kippt hier was oder bleibt es stabil?"

2. HINTERGRUND-MUSTER
   â†’ Erkennt aktivierte Muster
   â†’ "Was lÃ¤uft im Hintergrund wirklich?"

3. DRUCKFAKTOREN
   â†’ Identifiziert EinflÃ¼sse
   â†’ "Was drÃ¼ckt oder zieht hier?"

4. TIEFE
   â†’ Misst IntensitÃ¤t (1-7 Skala)
   â†’ "Wie tief geht das?"

5. WIRKUNG AUF BEIDE SEITEN
   â†’ Analysiert Sender/EmpfÃ¤nger
   â†’ "Wie kommt das auf Seite A/B an?"

6. KLARTEXT
   â†’ Raw Output ohne Filter
   â†’ "Worum geht es wirklich?"
```

### Warum menschliche Terminologie?

**Problem:** Technische Begriffe (DRIFTKÃ–RPER, SUBPROTOKOLL) klingen mechanisch

**LÃ¶sung:** Menschliche Begriffe (DRIFT, HINTERGRUND-MUSTER) bei gleicher PrÃ¤zision

**Resultat:** Model denkt in Feldern, spricht aber wie ein Mensch

---

## ğŸ“Š Quality Scoring

Jede Response wird automatisch bewertet:

### Scoring-Kriterien
```
Field Completeness (70%):
- Alle 6 Felder ausgefÃ¼llt?
- Gewichtet nach Wichtigkeit

Structure Adherence (30%):
- Nummerierung vorhanden?
- Format eingehalten?
```

### Score-Kategorien
```
95-100: Excellent â­â­â­â­â­
85-94:  Sehr gut â­â­â­â­
70-84:  Gut â­â­â­
50-69:  Okay â­â­
0-49:   Schwach â­
```

---

## ğŸ”§ Konfiguration

### API Endpoints
```python
# syntex_injector/syntex/api/config.py

API_ENDPOINT = "https://dev.syntx-system.com/api/chat"
READ_TIMEOUT = 1800  # 30 Minuten
MODEL_PARAMS = {
    "max_new_tokens": 1024,
    "temperature": 0.3,
    "top_p": 0.85,
    "do_sample": True
}
```

### Wrapper Anpassen
```bash
# Custom Wrapper erstellen
cp syntex_injector/syntex_wrapper.txt.template my_wrapper.txt

# Verwenden
python3 inject_syntex_enhanced.py -f prompt.txt -w my_wrapper.txt
```

---

## ğŸ“ Logging Format

### GPT-4 Prompts (`logs/gpt_prompts.jsonl`)
```json
{
  "timestamp": "2025-11-26T02:00:00Z",
  "success": true,
  "prompt_generated": "...",
  "quality_score": {
    "total_score": 7,
    "max_score": 10
  },
  "cost": {
    "total_cost": 0.001190,
    "currency": "USD"
  },
  "duration_ms": 3275
}
```

### SYNTEX Calibrations (`logs/syntex_calibrations.jsonl`)
```json
{
  "timestamp": "2025-11-26T02:05:00Z",
  "system": "SYNTEX::TRUE_RAW",
  "meta_prompt": "...",
  "response": "1. DRIFT: ...",
  "success": true,
  "quality_score": {
    "total_score": 98,
    "field_completeness": 100,
    "structure_adherence": 96,
    "detail_breakdown": {
      "drift": true,
      "hintergrund_muster": true,
      "druckfaktoren": true,
      "tiefe": true,
      "wirkung": true,
      "klartext": true
    }
  },
  "parsed_fields": {
    "drift": "...",
    "hintergrund_muster": "...",
    "druckfaktoren": "...",
    "tiefe": "...",
    "wirkung": "...",
    "klartext": "..."
  },
  "duration_ms": 36231
}
```

---

## ğŸ–¥ï¸ Production Deployment

### Cronjobs
```bash
# GPT-4 Batch (bereits aktiv)
0 2 * * * /opt/syntx-workflow-api-get-prompts/run_batch.sh 20

# SYNTEX Pipeline
0 3 * * * cd /opt/syntx-workflow-api-get-prompts/syntex_injector && python3 syntex_pipeline.py -b 20 -s casual >> /var/log/syntex-pipeline-cron.log 2>&1
```

### Log-Rotation
```bash
# /etc/logrotate.d/syntex
/var/log/syntex-*.log {
    daily
    rotate 30
    compress
    missingok
    notifempty
}
```

---

## ğŸ“ˆ Performance

### Benchmarks (Production)
```
GPT-4 Prompt Generation:
- Durchschnitt: 3-7 Sekunden
- Cost: $0.001-0.004 pro Prompt
- Quality: 7-8/10

SYNTEX Calibration (Llama 3):
- Durchschnitt: 25-40 Sekunden
- Quality Score: 95-98/100
- Field Completeness: 100%

Complete Pipeline:
- Total: 30-50 Sekunden
- Success Rate: 95%+
- Cost per Item: $0.001-0.004
```

### Empfohlene Batch-GrÃ¶ÃŸen
```
Development: 5-10 Prompts
Testing: 20 Prompts
Production: 20-50 Prompts/Tag
```

---

## ğŸ§ª Testing
```bash
# Basic Injector Test
cd syntex_injector
echo "Test Prompt" > test.txt
python3 inject_syntex_enhanced.py -f test.txt

# Pipeline Test
python3 syntex_pipeline.py -t "Test Topic" -s casual

# Batch Test
python3 syntex_pipeline.py -b 5

# Progress anzeigen
python3 inject_syntex_enhanced.py --show-progress
```

---

## ğŸ¤ Workflow

### Development Flow
```
1. GPT generiert diverse Prompts
   â†“
2. SYNTEX kalibriert sie
   â†“
3. Quality Tracking zeigt Verbesserung
   â†“
4. Bei Score 95+: Production-Ready
```

### Training Flow (Future)
```
1. Sammle 1000+ hochwertige SYNTEX-Responses
   â†“
2. Fine-tune Llama darauf
   â†“
3. Model lernt SYNTEX nativ
   â†“
4. Wrapper optional (Model denkt in Feldern)
```

---

## ğŸ’° Kosten

### GPT-4o
```
Input:  $2.50 / 1M tokens
Output: $10.00 / 1M tokens
Durchschnitt: ~$0.002 pro Prompt
```

### Monatliche Kosten (20 Prompts/Tag)
```
GPT-4: ~$1.20/Monat
Llama: Free (self-hosted)
Total: ~$1.20/Monat
```

---

## ğŸ› Troubleshooting

### Problem: 504 Timeout
```bash
# Timeout erhÃ¶hen
sed -i 's/READ_TIMEOUT = .*/READ_TIMEOUT = 1800/' syntex_injector/syntex/api/config.py
```

### Problem: Felder nicht erkannt
```bash
# Parser-Patterns prÃ¼fen
grep "PATTERNS = {" -A 20 syntex_injector/syntex/core/parser.py
```

### Problem: Quality Score niedrig
```bash
# Logs analysieren
tail -50 logs/syntex_calibrations.jsonl | jq '.quality_score'
```

---

## ğŸ“ Konzepte

### Token-Prediction vs. Feld-Kalibrierung

**Token-Based (Alte Welt):**
```
"What's the next most likely word?"
â†’ Approximation of meaning
â†’ Statistical patterns
```

**Field-Based (SYNTEX):**
```
"Where is the system in resonance space?"
â†’ Direct measurement of meaning
â†’ Semantic coordinates
```

### Warum SYNTEX funktioniert

1. **Strukturkraft:** 6 Felder sind universell
2. **Model-Agnostisch:** Jedes Model kann es lernen
3. **Resonanz-Logik:** Bedeutung als Feld, nicht als Sequenz
4. **Menschliche Terminologie:** NatÃ¼rlich aber prÃ¤zise

---

## ğŸ“š WeiterfÃ¼hrend

### NÃ¤chste Schritte

- [ ] Fine-tuning Dataset sammeln (1000+ Responses)
- [ ] Async Processing fÃ¼r lange Prompts
- [ ] Multi-Model Support (GPT-4, Claude, etc.)
- [ ] Visualisierung der Resonanzfelder
- [ ] API fÃ¼r externe Integration

---

## ğŸ‘¥ Team

**SYNTEX Development Team**

Entwickelt fÃ¼r semantische Resonanz-Analyse und AI-Training.

---

## ğŸ“„ License

MIT License

---

## ğŸ™ Acknowledgments

- OpenAI GPT-4o API
- Llama 3 (Meta)
- Python OpenAI SDK

---

**Developed with ğŸ”¥ for Resonance-Based AI**

---

## ğŸ”¥ Was macht SYNTEX besonders?

### Nicht nur ein Framework

**SYNTEX ist ein Protokoll** - Models passen sich dem Protokoll an, nicht umgekehrt.

### Emergentes System

Die Struktur hat EigenstÃ¤ndigkeit:
- Terminologie ist austauschbar
- Felder bleiben stabil
- Models Ã¼bernehmen es sofort

### Paradigmenwechsel
```
Von: "Was sagt die KI?"
Zu:  "Was misst das System?"
```

**Das ist der Unterschied zwischen Approximation und Kalibrierung.**

---

**Happy Calibrating! ğŸš€**
