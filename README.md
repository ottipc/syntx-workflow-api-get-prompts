

ğŸš€ SYNTX Workflow Trainer â€“ Automatisierte Prompt- & Analyse-Pipeline

(Technische Dokumentation fÃ¼r Entwickler, Forscher & Maintainer)

Der SYNTX Workflow Trainer ist ein modular aufgebautes System zur vollautomatischen Generierung, Verpackung, AusfÃ¼hrung und Auswertung von Prompts Ã¼ber verschiedene KI-Modelle hinweg.

Das System arbeitet:
	â€¢	modellagnostisch (GPT-4o, Claude, Gemini, DeepSeek, Llama, Mistral â€¦)
	â€¢	datenlos (keine statischen Trainingsdaten â€” Prompts werden dynamisch erzeugt)
	â€¢	skalierbar (Batch-Runs, Cronjobs, Message Queues)
	â€¢	erweiterbar (Wrapper, Parser, Scoring, Modelle, Logging-Backends)
	â€¢	resilient (vollstÃ¤ndiges Error-Handling & Retry-System)

Diese Pipeline bildet den Kern einer neuen Form der automatisierten Modellkalibrierung und Modellverhaltensmessung.

â¸»

ğŸ“ 1. Gesamtarchitektur

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WORKFLOW SYSTEM                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 1. Topic API â”‚  â†’ erzeugt Themen / Stichworte
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 2. Prompt Generator  â”‚  â†’ GPT/Claude/Gemini generieren Meta-Prompts
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 3. Wrapper Engine    â”‚  â†’ Human / Sigma / weitere Wrapper
   â”‚                      â”‚     ummanteln Meta-Prompt
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 4. Target Model Runner       â”‚  â†’ sendet Wrapped-Prompts an Llama/Mistral
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 5. Parsing & Scoring    â”‚  â†’ prÃ¼ft Struktur, VollstÃ¤ndigkeit, QualitÃ¤t
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 6. JSON Logging Engine       â”‚  â†’ speichert alles sauber formatiert
   â”‚                              â”‚    (SuperBase-ready)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ 7. Batch / Cron Scheduler    â”‚  â†’  Automatisches Tages-Training
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â¸»

ğŸ§© 2. Module im Detail

2.1 Topic Provider ğŸ”§

Generiert zufÃ¤llige oder definierte Themen.
	â€¢	zufÃ¤llig
	â€¢	manuell
	â€¢	aus Dateien
	â€¢	via Cronjob

â†’ Ãœbergibt an Prompt Generator.

â¸»

2.2 Prompt Generator (GPT/Claude/etc.) ğŸ¤–

Nutzt externe Modelle, um Meta-Prompts zu erzeugen.

Features:
	â€¢	Automatic retries
	â€¢	Configurable length
	â€¢	Temperature, Top-P
	â€¢	Error-Recovery
	â€¢	Kostenschonend (Meta-Prompts sind kurz)

Output wird in JSON geloggt.

â¸»

2.3 Wrapper Engine ğŸ“¦

Ummantelt die Meta-Prompts mit strukturellen Frameworks.

Aktuell implementiert:
	â€¢	Human-Wrapper (professionelle Analyse-Struktur)
	â€¢	Sigma-Wrapper (fortgeschrittene analytische Terminologie)

Wrapper sind austauschbar & erweiterbar.
Jeder Wrapper:
	â€¢	injiziert Struktur
	â€¢	erzeugt klare Analyse-Sektionen
	â€¢	bringt deterministische Formatierungsregeln
	â€¢	ist vollstÃ¤ndig offen & versionierbar

â¸»

2.4 Target Model Runner (Llama/Mistral) âš™ï¸

Sendet den fertigen Full-Prompt an das interne Modell.

Features:
	â€¢	Session IDs
	â€¢	Retry-Mechanismus
	â€¢	Timeout-Handling
	â€¢	Flexible Model-Selection (lokal/remote)
	â€¢	Dynamische Tokenlimits

â¸»

2.5 Parser & Scoring Engine ğŸ“Š

Analysiert die Antwort und prÃ¼ft:
	â€¢	StrukturkonformitÃ¤t
	â€¢	VollstÃ¤ndigkeit aller Rahmen-Elemente
	â€¢	QualitÃ¤t der Ausformulierung
	â€¢	Token-Verhalten
	â€¢	Konsistenz Ã¼ber mehrere Runs

Ergebnis: Quality Score (0â€“100)

â¸»

2.6 JSON Logging Engine ğŸ“

Alle Schritte werden in .jsonl geloggt:
	â€¢	Zeitstempel
	â€¢	Modell
	â€¢	Prompt-Input
	â€¢	Prompt-Output
	â€¢	Dauer
	â€¢	Erfolg/Fehler
	â€¢	Wrapper
	â€¢	Score

ğŸ“Œ Logformat ist bereits so gestaltet, dass es spÃ¤ter ohne Ã„nderungen in SuperBase importiert werden kann.

â¸»

2.7 Batch & Cron Scheduler â±ï¸

Batch-Runs via CLI:

python3 syntex_pipeline.py -b 10

Cronjobs (Beispiel):

0 6,12,18 * * * python3 syntex_pipeline.py -b 5


â¸»

ğŸ–¥ï¸ 3. Ordnerstruktur

syntx-workflow-api-get-prompts/
â”‚
â”œâ”€â”€ syntex_injector/
â”‚   â”œâ”€â”€ inject_syntex_enhanced.py
â”‚   â”œâ”€â”€ syntex_pipeline.py
â”‚   â”œâ”€â”€ wrappers/
â”‚   â”‚     â”œâ”€â”€ syntex_wrapper_human.txt
â”‚   â”‚     â”œâ”€â”€ syntex_wrapper_sigma.txt
â”‚   â”‚     â””â”€â”€ ...
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚     â”œâ”€â”€ core_parser.py
â”‚   â”‚     â””â”€â”€ sigma_parser.py
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚     â”œâ”€â”€ gpt_prompts.jsonl
â”‚   â”‚     â””â”€â”€ llama_responses.jsonl
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚     â”œâ”€â”€ test_syntex.txt
â”‚   â”‚     â””â”€â”€ topic_list.txt
â”‚   â””â”€â”€ utils/
â”‚         â”œâ”€â”€ api_call.py
â”‚         â”œâ”€â”€ json_logger.py
â”‚         â”œâ”€â”€ retry.py
â”‚         â””â”€â”€ timer.py
â”‚
â””â”€â”€ README.md


â¸»

ğŸ§  4. StÃ¤rken der Architektur

âœ”ï¸ Datenloses Training

Keine statischen Datasets â†’ volle Dynamik.

âœ”ï¸ Automatisierte Kalibrierung

Das Modell wird durch die Wrapper-Struktur erzogen.

âœ”ï¸ Modellagnostische Erweiterbarkeit

Neue APIs? Einfach neue Conf-Datei.

âœ”ï¸ Saubere Logs fÃ¼r Forschung & Debugging

Perfekt fÃ¼r spÃ¤tere Analysepipelines (z.B. SuperBase).

âœ”ï¸ Robuste Fehlerbehandlung

504, Timeouts, Rate-Limits â†’ alles abgefangen.

âœ”ï¸ Pipeline kann 24/7 laufen

Eine echte Trainingsmaschine.

â¸»

ğŸŒ± 5. ZukÃ¼nftige Erweiterungen
	â€¢	ğŸ”Œ Unified Wrapper Registry (Frontend-Wahl Human/Sigma/â€¦)
	â€¢	ğŸ—‚ï¸ SuperBase Storage & Querying
	â€¢	ğŸ“ˆ Web-Dashboard mit Live-Charts
	â€¢	ğŸ§µ RabbitMQ Integration
	â€¢	ğŸ§ª Evaluations-Benchmarking
	â€¢	ğŸ§© Multi-Model Sampling (Opus, Gemini, DeepSeek)

â¸»

ğŸ¯ 6. Ziel des Projekts

Ein System zu bauen, das:
	â€¢	sich selbst trainiert,
	â€¢	sich selbst erweitert,
	â€¢	ohne statische Daten auskommt,
	â€¢	und verschiedene Modelle miteinander verschaltet,
	â€¢	um emergentes Verhalten sichtbar zu machen.

â¸»

ğŸ™Œ 7. Mitwirkende
	â€¢	Ottavio â€“ Architektur, Konzept, Kodierung, Systemdesign
	â€¢	Max â€“ Model Deployment, Backend Infrastruktur
	â€¢	Community â€“ zukÃ¼nftige Contributions willkommen

â¸»

ğŸ 8. Licence

MIT â€” maximale Freiheit.

